{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers\n",
    "# !pip install datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HuggingFace\n",
    "- https://github.com/huggingface/transformers\n",
    "- NLP분야의 스타트업\n",
    "- 다양한 트랜스포머 모델(transformer.models)과 학습 스크립트(transformer.Trainer)를 제공하는 모듈\n",
    "- 개발자가 자연어 처리 애플리케이션과 서비스를 빠르고 효율적으로 구축하고 배포할 수 있도록 함"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "- 특정 작업을 수행하거나 특정 목표를 달성하기 위해 선형 또는 순차적 방식으로 연결된 일련의 프로세스\n",
    "- preprocess -> 모델 -> post process 생성\n",
    "- 최초 실행시 모델 다운로드\n",
    "- pipeline(task, model, config, tokenizer, ...)\n",
    "  - task : 내가 원하는 작업(ex. 'sentiment-analysis', 'zero-shot-classification', ...)\n",
    "  - model : 사용모델 (Default=task에 적절한 모델 할당)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 감정분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598049521446228}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-shot 분류\n",
    "- Zero-shot-Learning : 모델이 이전에 본 적이 없는 개체나 개념을 인식하도록 훈련되는 기계 학습\n",
    "- Zero-shot-Classification : 해당 클래스에 대한 명시적인 훈련 없이 이전에 본 적이 없는 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.9192408919334412, 0.060778193175792694, 0.01998087950050831]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\")   # Default Model = facebook/bart-large-mnli\n",
    "classifier(\n",
    "    \"This is a course about the transformers library\",           # 문제\n",
    "    candidate_labels = [\"education\", \"politics\", \"business\"],    # 정답보기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the transformers library',\n",
       " 'labels': ['course', 'library', 'This', 'game'],\n",
       " 'scores': [0.732907235622406,\n",
       "  0.19588284194469452,\n",
       "  0.06776876002550125,\n",
       "  0.003441136097535491]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\n",
    "    \"This is a course about the transformers library\",          # 문제\n",
    "    candidate_labels = [\"course\", \"library\", \"game\", \"This\"],    # 정답보기\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 생성모델\n",
    "- 문제로 주어진 문장을 기반으로 그 다음 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1219: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to \\xa0create simple, beautiful, dynamic design diagrams, and how to create them with a variety of basic software tools. We will make use of our favorite tools like Sketch, L.A. Sketch'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 세부조정\n",
    "- num_return_sequences : 문장갯수\n",
    "- max_length : 문장 길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to \\xa0communicate with fellow listeners.\\n2'},\n",
       " {'generated_text': 'In this course, we will teach you how to \\xa0install the new web application for PHP 5'},\n",
       " {'generated_text': 'In this course, we will teach you how to \\xa0understand the most basic \\xa0of'},\n",
       " {'generated_text': 'In this course, we will teach you how to \\xa0compete with the enemy. By taking'},\n",
       " {'generated_text': 'In this course, we will teach you how to \\xa0explicitly use the\\xa0cargo'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\"In this course, we will teach you how to \", num_return_sequences=5, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'In this course, we will teach you how to \\xa0help others get involved in social media.'}]\n",
      "[{'generated_text': 'This is a course about the transformers library.\\n\\nThis is part of the Meej'}]\n"
     ]
    }
   ],
   "source": [
    "list_ = [\"In this course, we will teach you how to \", \"This is a course about the transformers library\"]\n",
    "\n",
    "for sentence in list_:\n",
    "    print(generator(sentence, num_return_sequences=1, max_length=20))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HuggingFace 사이트에 있는 모델사용\n",
    "- 사용할 Task, Libraries 등 또는 Filter을 설정하고 원하는 모델을 찾기\n",
    "- 모델 포스팅 글에서 사용법 확인하고 적용하기\n",
    "![image](https://user-images.githubusercontent.com/118172599/236658858-5cf4ef58-7005-42f8-8a0e-9682d1ff3d3d.png)\n",
    "![image](https://user-images.githubusercontent.com/118172599/236659078-0704a318-e5eb-4799-ae90-3367ab3f7ae0.png)\n",
    "![image](https://user-images.githubusercontent.com/118172599/236659099-61f98aea-1231-4b11-8a31-59160d0ae7d4.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My dream is ive invented. ive invented what is basically the most popular movie ever made and I need over $10,000 to make it go away. Thank you.'},\n",
       " {'generated_text': 'My dream is ive been to be the next \"Powerball jack\"'},\n",
       " {'generated_text': 'My dream is ive come to the realization that i have the power of unlimited consciousness. I would get a brain if i could simply convince all the guys in the house where i live to stop smoking pot that i can still tell the difference between a man and a woman and I would become completely Normal'},\n",
       " {'generated_text': \"My dream is ive gotten over 1000 jobs. That's what my self believes. Ive fucked over 1000 people\"},\n",
       " {'generated_text': 'My dream is \\ue001� That the \\ue003� of humanity \\ue006nh is To See The \\ue006nht That Is As The \\ue001� Of My Dream.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"huggingtweets/dril\")\n",
    "generator(\"My dream is \", num_return_sequences=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이트에서도 실행가능\n",
    "![image](https://user-images.githubusercontent.com/118172599/236659251-a18e9e83-462c-4deb-ae82-124ca4e85ddf.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Filling\n",
    "- `<mask>`에 들어갈 단어 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.040895454585552216,\n",
       "  'token': 745,\n",
       "  'token_str': ' building',\n",
       "  'sequence': 'This coures will teach you all about building models'},\n",
       " {'score': 0.03127061203122139,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This coures will teach you all about mathematical models'},\n",
       " {'score': 0.025371771305799484,\n",
       "  'token': 774,\n",
       "  'token_str': ' role',\n",
       "  'sequence': 'This coures will teach you all about role models'},\n",
       " {'score': 0.01844116672873497,\n",
       "  'token': 265,\n",
       "  'token_str': ' business',\n",
       "  'sequence': 'This coures will teach you all about business models'},\n",
       " {'score': 0.015211271122097969,\n",
       "  'token': 3034,\n",
       "  'token_str': ' computer',\n",
       "  'sequence': 'This coures will teach you all about computer models'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This coures will teach you all about <mask> models\", top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.3025355935096741,\n",
       "  'token': 35950,\n",
       "  'token_str': ' tutorial',\n",
       "  'sequence': 'This tutorial will teach you all about classification models'},\n",
       " {'score': 0.1506633311510086,\n",
       "  'token': 1566,\n",
       "  'token_str': ' article',\n",
       "  'sequence': 'This article will teach you all about classification models'},\n",
       " {'score': 0.06644747406244278,\n",
       "  'token': 4704,\n",
       "  'token_str': ' guide',\n",
       "  'sequence': 'This guide will teach you all about classification models'},\n",
       " {'score': 0.06263384968042374,\n",
       "  'token': 768,\n",
       "  'token_str': ' course',\n",
       "  'sequence': 'This course will teach you all about classification models'},\n",
       " {'score': 0.05955677106976509,\n",
       "  'token': 1040,\n",
       "  'token_str': ' book',\n",
       "  'sequence': 'This book will teach you all about classification models'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"This <mask> will teach you all about classification models\", top_k=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그룹 엔티티\n",
    "- 학습되지 않은 단어의 클래스 찾기\n",
    "- Sylvain: Person, Hugging Face: Organization, Brooklyn: Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d078834d6be4b86ac355583fb529e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df99b6bb92a64073aa0edb8656a03643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae26162318540cf8b6546a20325fe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\pipelines\\token_classification.py:168: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9981694,\n",
       "  'word': 'Sylvain',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9796019,\n",
       "  'word': 'Hugging Face',\n",
       "  'start': 33,\n",
       "  'end': 45},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9932106,\n",
       "  'word': 'Brooklyn',\n",
       "  'start': 49,\n",
       "  'end': 57}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA\n",
    "- Query text : 나는 집에 들어갔다. 그런데 배고파서 햄버거를 먹었다\n",
    "- Question : 누가 햄버거를 먹었나?\n",
    "- Answer : 나"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9988495111465454, 'start': 11, 'end': 18, 'answer': 'Sylvain'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answer = pipeline(\"question-answering\")\n",
    "question_answer(\n",
    "    question=\"what's my name?\",\n",
    "    context=\"My name is Sylvain and I work at Hugging Face in Brooklyn.\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## summary\n",
    "- 한계점 : 긴 문장에서 일부분을 추출해서 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26211780ac82443594d37f72cfb8d9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a94ca28062b4922a9b2a3d1d3e31493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fc557f2f9845eea14fb07d378f0c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1701ae86fe249babb40c243fe012ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': \" Saudi Arabia's largest lender National Commercial Bank agrees to buy rival Samba Financial Group for $15 billion . NCB will pay 28.45 riyals ($7.58) for each Samba share, valuing it at about 55.7 billion . The new bank will have total assets of more than $220 billion, creating the Gulf region’s third-largest lender .\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    National Commercial Bank (NCB), \n",
    "    Saudi Arabia’s largest lender by assets, \n",
    "    agreed to buy rival Samba Financial Group for $15 billion in the biggest banking takeover this year.\n",
    "    NCB will pay 28.45 riyals ($7.58) for each Samba share, according to a statement on Sunday, \n",
    "    valuing it at about 55.7 billion riyals. NCB will offer 0.739 new shares for each Samba share, \n",
    "    at the lower end of the 0.736-0.787 ratio the banks set when they signed an initial framework \n",
    "    agreement in June.The offer is a 3.5% premium to Samba’s Oct. 8 closing price of 27.50 riyals and \n",
    "    about 24% higher than the level the shares traded at before the talks were made public. Bloomberg \n",
    "    News first reported the merger discussions.The new bank will have total assets of more than $220 billion, \n",
    "    creating the Gulf region’s third-largest lender. The entity’s $46 billion market capitalization nearly matches \n",
    "    that of Qatar National Bank QPSC, which is still the Middle East’s biggest lender with about $268 billion of \n",
    "    assets.\n",
    "    \"\"\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
